{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USG Failure Prediction - Feature Engineering\n",
    "\n",
    "**Objective:** Transform raw data into predictive features\n",
    "\n",
    "**Key Techniques:**\n",
    "- Batch quality indicators\n",
    "- Interaction features\n",
    "- Supplier-based aggregates\n",
    "- Anomaly scores\n",
    "- Time-series features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# Import preprocessing pipeline\n",
    "from preprocessing import USGPreprocessingPipeline\n",
    "\n",
    "# Configure\n",
    "np.random.seed(42)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline\n",
    "\n",
    "print(f\"Feature Engineering started: {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw data\n",
    "DATA_PATH = '../data/raw/USG_Data_cleared.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    print(f\"✓ Data loaded: {df.shape}\")\n",
    "    \n",
    "    # Separate features and target\n",
    "    if 'Warranty_Claim' in df.columns:\n",
    "        X = df.drop('Warranty_Claim', axis=1)\n",
    "        y = df['Warranty_Claim']\n",
    "        print(f\"✓ Features: {X.shape[1]}, Target distribution:\")\n",
    "        print(y.value_counts())\n",
    "    else:\n",
    "        print(\"⚠ Warning: Warranty_Claim column not found\")\n",
    "        X = df.copy()\n",
    "        y = None\n",
    "        \n",
    "except FileNotFoundError:\n",
    "    print(f\"⚠ Data file not found at {DATA_PATH}\")\n",
    "    X, y = None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if X is not None:\n",
    "    # Create preprocessing pipeline\n",
    "    preprocessor = USGPreprocessingPipeline(seed=42)\n",
    "    \n",
    "    print(\"Preprocessing Pipeline Initialized\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"Pipeline Components:\")\n",
    "    print(\"  1. Data leakage removal\")\n",
    "    print(\"  2. Batch feature engineering\")\n",
    "    print(\"  3. Interaction feature creation\")\n",
    "    print(\"  4. Supplier-based encoding\")\n",
    "    print(\"  5. Time-series features\")\n",
    "    print(\"  6. Categorical encoding\")\n",
    "    print(\"  7. Anomaly score generation\")\n",
    "    print(\"  8. Missing value imputation\")\n",
    "    print(\"  9. Feature scaling\")\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Apply Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if X is not None and y is not None:\n",
    "    # Fit and transform\n",
    "    print(\"Applying feature engineering pipeline...\\n\")\n",
    "    X_transformed = preprocessor.fit_transform(X, y)\n",
    "    \n",
    "    print(f\"\\n✓ Transformation complete\")\n",
    "    print(f\"  Original features: {X.shape[1]}\")\n",
    "    print(f\"  Engineered features: {X_transformed.shape[1]}\")\n",
    "    print(f\"  New features created: {X_transformed.shape[1] - X.shape[1]}\")\n",
    "    \n",
    "    # Display sample\n",
    "    print(\"\\nSample of transformed data:\")\n",
    "    display(X_transformed.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if X is not None and 'X_transformed' in locals():\n",
    "    # Get feature names\n",
    "    feature_names = preprocessor.get_feature_names()\n",
    "    \n",
    "    # Identify engineered features\n",
    "    engineered_features = [\n",
    "        feat for feat in feature_names \n",
    "        if any(keyword in feat for keyword in \n",
    "               ['_x_', '_div_', 'Batch_Age', 'Batch_Failure_Rate', \n",
    "                'Batch_Size', 'Failure_Rate', 'Anomaly', 'Serial_Position'])\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\nEngineered Features ({len(engineered_features)}):\")\n",
    "    print(\"-\" * 60)\n",
    "    for feat in engineered_features:\n",
    "        print(f\"  - {feat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'X_transformed' in locals() and 'engineered_features' in locals():\n",
    "    # Visualize engineered features distribution\n",
    "    if len(engineered_features) > 0:\n",
    "        n_features = min(9, len(engineered_features))\n",
    "        \n",
    "        fig, axes = plt.subplots(3, 3, figsize=(18, 12))\n",
    "        axes = axes.ravel()\n",
    "        \n",
    "        for idx, feat in enumerate(engineered_features[:n_features]):\n",
    "            if feat in X_transformed.columns:\n",
    "                axes[idx].hist(X_transformed[feat].dropna(), bins=50, \n",
    "                             color='steelblue', edgecolor='black')\n",
    "                axes[idx].set_title(feat, fontweight='bold')\n",
    "                axes[idx].set_xlabel('Value')\n",
    "                axes[idx].set_ylabel('Frequency')\n",
    "        \n",
    "        for idx in range(n_features, 9):\n",
    "            axes[idx].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('../reports/visualizations/engineered_features.png', \n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Correlation with Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'X_transformed' in locals() and y is not None:\n",
    "    # Calculate correlation with target\n",
    "    y_binary = (y == 'Yes').astype(int)\n",
    "    \n",
    "    # Combine for correlation\n",
    "    df_with_target = X_transformed.copy()\n",
    "    df_with_target['Target'] = y_binary\n",
    "    \n",
    "    # Calculate correlations\n",
    "    correlations = df_with_target.corr()['Target'].drop('Target')\n",
    "    correlations = correlations.abs().sort_values(ascending=False)\n",
    "    \n",
    "    print(\"Top 20 Features by Correlation with Target:\")\n",
    "    print(\"=\"*60)\n",
    "    display(correlations.head(20))\n",
    "    \n",
    "    # Visualization\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    correlations.head(20).plot(kind='barh', color='teal')\n",
    "    plt.title('Top 20 Features by Correlation with Warranty Claim', \n",
    "             fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Absolute Correlation')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../reports/visualizations/feature_target_correlation.png', \n",
    "               dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'X_transformed' in locals() and y is not None:\n",
    "    # Save processed data\n",
    "    X_transformed.to_csv('../data/processed/X_processed.csv', index=False)\n",
    "    y.to_csv('../data/processed/y_target.csv', index=False)\n",
    "    \n",
    "    print(\"✓ Processed data saved to data/processed/\")\n",
    "    print(f\"  - X_processed.csv: {X_transformed.shape}\")\n",
    "    print(f\"  - y_target.csv: {y.shape}\")\n",
    "    \n",
    "    # Save preprocessor\n",
    "    import joblib\n",
    "    joblib.dump(preprocessor, '../models/preprocessor.pkl')\n",
    "    print(\"\\n✓ Preprocessor saved to models/preprocessor.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'X_transformed' in locals():\n",
    "    print(\"=\"*80)\n",
    "    print(\"FEATURE ENGINEERING SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nOriginal Features: {X.shape[1]}\")\n",
    "    print(f\"Engineered Features: {X_transformed.shape[1]}\")\n",
    "    print(f\"Total New Features: {X_transformed.shape[1] - X.shape[1]}\")\n",
    "    \n",
    "    print(\"\\nFeature Engineering Techniques Applied:\")\n",
    "    print(\"  ✓ Batch quality indicators (age, failure rate, size)\")\n",
    "    print(\"  ✓ Interaction features (multiplicative & ratio)\")\n",
    "    print(\"  ✓ Supplier failure rate encoding\")\n",
    "    print(\"  ✓ Anomaly detection scores\")\n",
    "    print(\"  ✓ Time-series features from serial numbers\")\n",
    "    print(\"  ✓ Label encoding for categoricals\")\n",
    "    print(\"  ✓ Missing value imputation\")\n",
    "    print(\"  ✓ Feature scaling (standardization)\")\n",
    "    \n",
    "    print(\"\\nNext Steps:\")\n",
    "    print(\"  → Model Training with XGBoost (Notebook 03)\")\n",
    "    print(\"  → Hyperparameter optimization with Optuna\")\n",
    "    print(\"  → Ensemble methods\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"Feature engineering completed: {datetime.now()}\")\n",
    "    print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
