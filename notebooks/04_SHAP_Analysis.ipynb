{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USG Failure Prediction - SHAP Interpretability Analysis\n",
    "\n",
    "**Objective:** Explain model predictions for business stakeholders\n",
    "\n",
    "**Key Analyses:**\n",
    "- SHAP summary plot (global feature importance)\n",
    "- SHAP waterfall plots (individual predictions)\n",
    "- Partial Dependence Plots (PDP)\n",
    "- Feature importance comparison\n",
    "- Business insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure\n",
    "np.random.seed(42)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "shap.initjs()\n",
    "%matplotlib inline\n",
    "\n",
    "print(f\"SHAP Analysis started: {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Model and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model\n",
    "try:\n",
    "    model = joblib.load('../models/model.pkl')\n",
    "    print(\"✓ Model loaded successfully\")\n",
    "except FileNotFoundError:\n",
    "    print(\"⚠ Model not found. Please run Notebook 03 first.\")\n",
    "    model = None\n",
    "\n",
    "# Load test data\n",
    "try:\n",
    "    X = pd.read_csv('../data/processed/X_processed.csv')\n",
    "    y = pd.read_csv('../data/processed/y_target.csv').squeeze()\n",
    "    print(f\"✓ Data loaded: {X.shape}\")\n",
    "    \n",
    "    # Split to get test set (same random state as training)\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    print(f\"✓ Test set: {X_test.shape}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"⚠ Processed data not found. Please run Notebook 02 first.\")\n",
    "    X_test, y_test = None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize SHAP Explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model is not None and X_test is not None:\n",
    "    print(\"Initializing SHAP explainer...\")\n",
    "    print(\"This may take 1-2 minutes...\\n\")\n",
    "    \n",
    "    # Sample data for background (use subset for speed)\n",
    "    X_background = shap.sample(X_train, 100, random_state=42)\n",
    "    \n",
    "    # Create TreeExplainer for tree-based models\n",
    "    # Get the base model from the calibrated wrapper\n",
    "    if hasattr(model, 'model'):\n",
    "        if hasattr(model.model, 'calibrated_model'):\n",
    "            base_estimator = model.model.calibrated_model.calibrated_classifiers_[0].estimator\n",
    "        else:\n",
    "            base_estimator = model.model\n",
    "    else:\n",
    "        base_estimator = model\n",
    "    \n",
    "    explainer = shap.TreeExplainer(base_estimator)\n",
    "    \n",
    "    # Calculate SHAP values for test set\n",
    "    print(\"Calculating SHAP values for test set...\")\n",
    "    shap_values = explainer.shap_values(X_test)\n",
    "    \n",
    "    # For binary classification, get positive class\n",
    "    if isinstance(shap_values, list):\n",
    "        shap_values_positive = shap_values[1]\n",
    "    else:\n",
    "        shap_values_positive = shap_values\n",
    "    \n",
    "    print(f\"\\n✓ SHAP values computed: {shap_values_positive.shape}\")\n",
    "    \n",
    "    # Save explainer for API\n",
    "    joblib.dump(explainer, '../models/shap_explainer.pkl')\n",
    "    print(\"✓ SHAP explainer saved to models/shap_explainer.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. SHAP Summary Plot - Global Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'shap_values_positive' in locals():\n",
    "    # Summary plot (beeswarm)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    shap.summary_plot(shap_values_positive, X_test, max_display=20, show=False)\n",
    "    plt.title('SHAP Summary Plot - Top 20 Features', fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../reports/visualizations/shap_summary_plot.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"✓ SHAP summary plot saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. SHAP Bar Plot - Mean Absolute Impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'shap_values_positive' in locals():\n",
    "    # Bar plot showing mean absolute SHAP values\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    shap.summary_plot(shap_values_positive, X_test, plot_type=\"bar\", \n",
    "                     max_display=20, show=False)\n",
    "    plt.title('Feature Importance - Mean |SHAP Value|', fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../reports/visualizations/shap_bar_plot.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Get top features\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X_test.columns,\n",
    "        'importance': np.abs(shap_values_positive).mean(axis=0)\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nTop 20 Most Important Features:\")\n",
    "    print(\"=\"*60)\n",
    "    display(feature_importance.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. SHAP Waterfall Plots - Individual Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'shap_values_positive' in locals():\n",
    "    # Find examples: one failure, one no-failure\n",
    "    failure_idx = y_test[y_test == 'Yes'].index[0]\n",
    "    no_failure_idx = y_test[y_test == 'No'].index[0]\n",
    "    \n",
    "    # Get positions in test set\n",
    "    failure_pos = X_test.index.get_loc(failure_idx)\n",
    "    no_failure_pos = X_test.index.get_loc(no_failure_idx)\n",
    "    \n",
    "    # Create explanation objects\n",
    "    base_value = explainer.expected_value\n",
    "    if isinstance(base_value, list):\n",
    "        base_value = base_value[1]\n",
    "    \n",
    "    # Waterfall for failure case\n",
    "    print(\"\\nExample 1: Device with Warranty Claim (Failure)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    explanation_failure = shap.Explanation(\n",
    "        values=shap_values_positive[failure_pos],\n",
    "        base_values=base_value,\n",
    "        data=X_test.iloc[failure_pos].values,\n",
    "        feature_names=X_test.columns.tolist()\n",
    "    )\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    shap.plots.waterfall(explanation_failure, max_display=20, show=False)\n",
    "    plt.title('SHAP Waterfall - Failure Case', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../reports/visualizations/shap_waterfall_failure.png', \n",
    "               dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Waterfall for no-failure case\n",
    "    print(\"\\nExample 2: Device without Warranty Claim (No Failure)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    explanation_no_failure = shap.Explanation(\n",
    "        values=shap_values_positive[no_failure_pos],\n",
    "        base_values=base_value,\n",
    "        data=X_test.iloc[no_failure_pos].values,\n",
    "        feature_names=X_test.columns.tolist()\n",
    "    )\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    shap.plots.waterfall(explanation_no_failure, max_display=20, show=False)\n",
    "    plt.title('SHAP Waterfall - No Failure Case', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../reports/visualizations/shap_waterfall_no_failure.png', \n",
    "               dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Partial Dependence Plots (PDP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'feature_importance' in locals():\n",
    "    # Get top 10 features for PDP\n",
    "    top_features = feature_importance.head(10)['feature'].tolist()\n",
    "    \n",
    "    print(f\"Creating Partial Dependence Plots for top {len(top_features)} features...\")\n",
    "    \n",
    "    # Create SHAP dependence plots\n",
    "    fig, axes = plt.subplots(5, 2, figsize=(16, 20))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for idx, feature in enumerate(top_features[:10]):\n",
    "        feature_idx = X_test.columns.get_loc(feature)\n",
    "        \n",
    "        plt.sca(axes[idx])\n",
    "        shap.dependence_plot(\n",
    "            feature_idx, \n",
    "            shap_values_positive, \n",
    "            X_test,\n",
    "            show=False,\n",
    "            ax=axes[idx]\n",
    "        )\n",
    "        axes[idx].set_title(f'Dependence: {feature}', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../reports/visualizations/shap_dependence_plots.png', \n",
    "               dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"✓ Dependence plots saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Importance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model is not None and 'feature_importance' in locals():\n",
    "    # Get XGBoost native importance\n",
    "    try:\n",
    "        # Extract base XGBoost model\n",
    "        if hasattr(model, 'model'):\n",
    "            if hasattr(model.model, 'calibrated_model'):\n",
    "                xgb_model = model.model.calibrated_model.calibrated_classifiers_[0].estimator\n",
    "            else:\n",
    "                xgb_model = model.model\n",
    "        else:\n",
    "            xgb_model = model\n",
    "        \n",
    "        # Check if it's an ensemble\n",
    "        if hasattr(xgb_model, 'estimators_'):\n",
    "            # Get XGBoost from ensemble\n",
    "            for name, estimator in xgb_model.estimators_:\n",
    "                if 'xgb' in name.lower():\n",
    "                    xgb_base = estimator\n",
    "                    break\n",
    "        else:\n",
    "            xgb_base = xgb_model\n",
    "        \n",
    "        # Get feature importances\n",
    "        if hasattr(xgb_base, 'feature_importances_'):\n",
    "            gain_importance = pd.DataFrame({\n",
    "                'feature': X_test.columns,\n",
    "                'gain': xgb_base.feature_importances_\n",
    "            }).sort_values('gain', ascending=False)\n",
    "            \n",
    "            # Compare with SHAP\n",
    "            comparison = feature_importance.merge(\n",
    "                gain_importance, on='feature', how='left'\n",
    "            ).head(20)\n",
    "            \n",
    "            # Normalize for comparison\n",
    "            comparison['importance_norm'] = comparison['importance'] / comparison['importance'].max()\n",
    "            comparison['gain_norm'] = comparison['gain'] / comparison['gain'].max()\n",
    "            \n",
    "            # Plot comparison\n",
    "            fig, ax = plt.subplots(figsize=(14, 8))\n",
    "            \n",
    "            x = np.arange(len(comparison))\n",
    "            width = 0.35\n",
    "            \n",
    "            ax.barh(x - width/2, comparison['importance_norm'], width, \n",
    "                   label='SHAP Importance', color='steelblue')\n",
    "            ax.barh(x + width/2, comparison['gain_norm'], width, \n",
    "                   label='XGBoost Gain', color='coral')\n",
    "            \n",
    "            ax.set_yticks(x)\n",
    "            ax.set_yticklabels(comparison['feature'])\n",
    "            ax.set_xlabel('Normalized Importance', fontsize=12)\n",
    "            ax.set_title('Feature Importance Comparison: SHAP vs XGBoost Gain', \n",
    "                        fontsize=14, fontweight='bold')\n",
    "            ax.legend()\n",
    "            ax.invert_yaxis()\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig('../reports/visualizations/feature_importance_comparison.png', \n",
    "                       dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "            \n",
    "            print(\"\\nFeature Importance Comparison (Top 10):\")\n",
    "            display(comparison[['feature', 'importance', 'gain']].head(10))\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Could not extract XGBoost importances: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Business Insights from SHAP Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'feature_importance' in locals():\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"BUSINESS INSIGHTS FROM SHAP ANALYSIS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    top_10_features = feature_importance.head(10)\n",
    "    \n",
    "    print(\"\\n1. CRITICAL FAILURE PREDICTORS:\")\n",
    "    print(\"-\" * 80)\n",
    "    for idx, row in top_10_features.iterrows():\n",
    "        print(f\"   {idx+1}. {row['feature']}: {row['importance']:.4f}\")\n",
    "    \n",
    "    print(\"\\n2. ACTIONABLE RECOMMENDATIONS:\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Identify feature categories\n",
    "    supplier_features = [f for f in top_10_features['feature'] if 'Supplier' in f]\n",
    "    batch_features = [f for f in top_10_features['feature'] if 'Batch' in f]\n",
    "    temp_features = [f for f in top_10_features['feature'] if 'Temp' in f]\n",
    "    interaction_features = [f for f in top_10_features['feature'] if '_x_' in f or '_div_' in f]\n",
    "    \n",
    "    if supplier_features:\n",
    "        print(\"\\n   SUPPLIER QUALITY:\")\n",
    "        print(f\"   - {len(supplier_features)} supplier-related features in top 10\")\n",
    "        print(\"   - Action: Review and audit high-risk suppliers\")\n",
    "        print(\"   - Action: Implement supplier qualification programs\")\n",
    "    \n",
    "    if batch_features:\n",
    "        print(\"\\n   BATCH MONITORING:\")\n",
    "        print(f\"   - {len(batch_features)} batch-related features in top 10\")\n",
    "        print(\"   - Action: Enhance batch-level quality controls\")\n",
    "        print(\"   - Action: Implement real-time batch anomaly detection\")\n",
    "    \n",
    "    if temp_features:\n",
    "        print(\"\\n   ENVIRONMENTAL CONTROLS:\")\n",
    "        print(f\"   - {len(temp_features)} temperature-related features in top 10\")\n",
    "        print(\"   - Action: Tighten environmental parameter tolerances\")\n",
    "        print(\"   - Action: Install real-time monitoring systems\")\n",
    "    \n",
    "    if interaction_features:\n",
    "        print(\"\\n   PROCESS INTERACTIONS:\")\n",
    "        print(f\"   - {len(interaction_features)} interaction features in top 10\")\n",
    "        print(\"   - Action: Optimize parameter combinations\")\n",
    "        print(\"   - Action: Avoid extreme parameter pairings\")\n",
    "    \n",
    "    print(\"\\n3. DEPLOYMENT STRATEGY:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(\"   - Use SHAP waterfall plots in production for each prediction\")\n",
    "    print(\"   - Alert quality team when high-risk devices detected\")\n",
    "    print(\"   - Generate weekly reports on feature trends\")\n",
    "    print(\"   - Integrate with manufacturing execution system (MES)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SHAP ANALYSIS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nVisualizations Created:\")\n",
    "print(\"  ✓ SHAP Summary Plot (beeswarm)\")\n",
    "print(\"  ✓ SHAP Bar Plot (mean absolute impact)\")\n",
    "print(\"  ✓ SHAP Waterfall Plots (2 examples)\")\n",
    "print(\"  ✓ Partial Dependence Plots (top 10 features)\")\n",
    "print(\"  ✓ Feature Importance Comparison\")\n",
    "\n",
    "print(\"\\nArtifacts Saved:\")\n",
    "print(\"  ✓ SHAP explainer (models/shap_explainer.pkl)\")\n",
    "print(\"  ✓ All visualizations (reports/visualizations/)\")\n",
    "\n",
    "print(\"\\nKey Findings:\")\n",
    "if 'top_10_features' in locals():\n",
    "    print(f\"  - {len(top_10_features)} critical features identified\")\n",
    "    print(f\"  - Top feature: {top_10_features.iloc[0]['feature']}\")\n",
    "    print(\"  - Model is fully interpretable for business use\")\n",
    "\n",
    "print(\"\\nNext Steps:\")\n",
    "print(\"  → Deploy API with SHAP explanations (src/api.py)\")\n",
    "print(\"  → Generate business report\")\n",
    "print(\"  → Present findings to stakeholders\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"SHAP analysis completed: {datetime.now()}\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
